This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-10-20T13:28:23.104Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.gitignore
agents/agent_factory.py
agents/agent.py
app.py
main.py
README.md
utils/result_formatter.py
utils/user_input_handler.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Python-related
__pycache__/
*.py[cod]
*.so
*.egg
*.egg-info/
dist/
build/
*.egg-info/
.eggs/

# Virtual environments
venv/
env/
.venv/
.env/

# IDEs and editors
.vscode/
.idea/
*.swp
*.swo
*~

# OS-specific
.DS_Store
Thumbs.db

# Project-specific
logs/*.log
!logs/.gitkeep

# API keys and secrets
.env

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# Log files
*.log
.aider*

================
File: agents/agent_factory.py
================
from .agent import Agent

class AgentFactory:
    def __init__(self):
        self.agent_prompts = [
            (
                'Agent1',
                """
你是Agent1,一位专门通过深入的思维链推理提供初步解决方案的专家问题解决者。

**你的目标:**
- 深入理解问题。
- 提供详细的、逐步的解决方案。
- 如果适用,包含并测试代码片段以验证你的解决方案。
- 反思并迭代你的解决方案,直到有信心为止。

**指示:**
- 在每个推理步骤之后,决定是否需要继续完善你的推理,或者是否准备好将你的解决方案传递给下一个agent。
- 使用至少三种不同的方法来验证你的答案。
- 明确指出你推理中的任何不确定性或假设。

**响应格式:**
以JSON格式响应,包含以下键:
- "title": 推理步骤的简短标题。
- "content": 推理步骤的详细解释。
- "next_action": 如果继续进行更多步骤则为"continue",如果你对解决方案有信心则为"final_answer"。

如果代码片段有助于你的解决方案,请将其包含在三个反引号内(```python)。

**示例响应:**
```json
{
    "title": "分析问题",
    "content": "为了解决这个问题,我首先会...",
    "next_action": "continue"
}
"""
            ),
            (
                'Agent2',
                """
你是Agent2,一位通过深入反思来审查解决方案并加以改进的批判性分析者。

**你的目标:**

- 批判性地分析先前的解决方案。
- 识别优势和需要改进的地方。
- 提供具体的改进。
- 反思并迭代你的解决方案,直到有信心为止。

**指示:**

1. **解决方案审查:**

   - 总结先前解决方案的要点。
   - 识别任何错误、遗漏或需要改进的地方。

2. **改进:**

   - 对解决方案提供具体的改进。
   - 纠正任何错误或误解。
   - 如果代码片段有助于你的解决方案,请将其包含在三个反引号内(```python)。

3. **代码测试:**

   - 执行你的代码以测试其正确性。
   - 使用结果来验证或完善你的改进。

4. **反思和迭代:**

   - 批判性地评估你修改后的解决方案。
   - 决定是继续完善还是进入下一个agent。

5. **最终答案:**

   - 清晰地呈现你改进后的解决方案。

6. **信心评级:**

   - 提供一个信心评级(1-10)并解释理由。

**响应格式:**

以JSON格式响应,包含以下键:

- `"title"`: 推理步骤的简短标题。
- `"content"`: 推理步骤的详细解释。
- `"next_action"`: 如果继续进行更多步骤则为`"continue"`,如果你对解决方案有信心则为`"final_answer"`。

**示例响应:**

```json
{
    "title": "增强解决方案",
    "content": "在审查后,我注意到...",
    "next_action": "continue"
}
"""
            ),
            (
                'Agent3',
                """
你是Agent3,一位通过融入高级见解并确保准确性来完善解决方案的主题专家。

**你的目标:**

- 评估修改后的解决方案的技术正确性。
- 融入高级概念或方法。
- 反思并迭代你的解决方案,直到有信心为止。

**指示:**

1. **专家分析:**

   - 评估解决方案的技术准确性。
   - 识别可以应用的任何高级概念或方法。

2. **改进:**

   - 将高级见解融入解决方案。
   - 如果代码片段有助于你的解决方案,请将其包含在三个反引号内(```python)。

3. **代码测试:**

   - 执行你的代码以测试其正确性。
   - 使用结果来验证或完善你的改进。

4. **反思和迭代:**

   - 批判性地评估改进后的解决方案。
   - 决定是继续完善还是进入下一个agent。

5. **最终答案:**

   - 清晰地呈现你完善后的解决方案。

6. **信心评级:**

   - 提供一个信心评级(1-10)并解释理由。

**响应格式:**

以JSON格式响应,包含以下键:

- `"title"`: 推理步骤的简短标题。
- `"content"`: 推理步骤的详细解释。
- `"next_action"`: 如果继续进行更多步骤则为`"continue"`,如果你对解决方案有信心则为`"final_answer"`。

**示例响应:**

```json
{
    "title": "应用高级概念",
    "content": "为了增强解决方案,我将...",
    "next_action": "continue"
}
"""
            ),
            (
                'Agent4',
                """
你是Agent4,一位确保解决方案正确、全面且表述良好的最终审核者。

**你的目标:**

- 进行彻底的最终审查。
- 解决任何剩余问题。
- 提供最终的精炼解决方案。
- 反思对答案的整体信心。

**指示:**

1. **最终审查:**

   - 仔细阅读整个解决方案。
   - 检查是否还有任何错误或不一致之处。

2. **完善:**

   - 改进解决方案的表述和清晰度。
   - 确保逻辑流畅和可读性。
   - 如果代码片段有助于你的解决方案,请将其包含在三个反引号内(```python)。

3. **代码测试:**

   - 执行任何代码以确认其正确性。
   - 使用结果来完成解决方案。

4. **反思和总结:**

   - 反思解决方案的整体质量。
   - 决定是否需要进一步完善。

5. **最终答案:**

   - 呈现最终精炼的解决方案。

6. **信心评级:**

   - 提供最终的信心评级(1-10)并解释理由。

**响应格式:**

以JSON格式响应,包含以下键:

- `"title"`: "最终审查和总结"
- `"content"`: 你的最终审查和精炼解决方案的详细解释。
- `"next_action"`: "final_answer"

**示例响应:**

```json
{
    "title": "最终审查和总结",
    "content": "经过彻底审查,最终解决方案是...",
    "next_action": "final_answer"
}
"""
            )
        ]

    def create_agents(self):
        agents = []
        for name, prompt in self.agent_prompts:
            agents.append(Agent(name, prompt))
        return agents

================
File: agents/agent.py
================
# agents/agent.py

import logging
import os
import openai
from openai import OpenAI
import re
import json
import time

logger = logging.getLogger(__name__)

class Agent:
    def __init__(self, name, role_prompt):
        self.name = name
        self.role_prompt = role_prompt

    def get_solution(self, problem, previous_solution=None):
        messages = []

        # System prompt
        messages.append({"role": "system", "content": self.role_prompt})

        # User prompt
        if previous_solution:
            messages.append({"role": "user", "content": f"Problem:\n{problem}\n\nPrevious Solution:\n{previous_solution}\n\nPlease proceed with your analysis."})
        else:
            messages.append({"role": "user", "content": f"Problem:\n{problem}\n\nPlease provide your solution."})

        # Assistant initial acknowledgment
        messages.append({"role": "assistant", "content": "Understood. I will begin my reasoning steps now."})

        steps = []
        step_count = 1

        while True:
            # Build the prompt for the current reasoning step
            prompt = self.build_prompt(messages)

            try:
                response_text = self.make_api_call(prompt)
                print(response_text)
                if not response_text:
                    logger.error(f"{self.name} did not return a valid response.")
                    break
                
                # 直接将response_text添加到steps中
                steps.append((f"Step {step_count}", response_text))

                messages.append({"role": "assistant", "content": response_text})

                # 检查是否是最终答案
                if "final_answer" in response_text.lower():
                    break

                print(step_count)

                step_count += 1

            except Exception as e:
                logger.error(f"Unexpected error in {self.name}: {str(e)}")
                break

        # Compile the agent's solution
        agent_solution = self.compile_solution(steps)
        logger.info(f"{self.name} completed their solution with steps: {steps}")
        return agent_solution

    def build_prompt(self, messages):
        # Combine messages into a single prompt
        prompt = ''
        for message in messages:
            role = message['role']
            content = message['content']
            if role == 'system':
                prompt += f"System: {content}\n\n"
            elif role == 'user':
                prompt += f"User: {content}\n\n"
            elif role == 'assistant':
                prompt += f"Assistant: {content}\n\n"
        return prompt

    def make_api_call(self, prompt):
        # 配置 API 密钥
        openai.api_key = os.getenv("OPENAI_API_KEY")  # 请确保在环境变量中设置 OPENAI_API_KEY
        os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'
        try:
            # 调用 OpenAI 的 ChatCompletion API 来生成响应
            client = OpenAI()
            response = client.chat.completions.create(
                model="gpt-4o",  # 选择要使用的模型，可以是 "gpt-3.5-turbo" 或 "gpt-4"
                messages=[
                    {"role": "system", "content": self.role_prompt},  # 系统角色的提示
                    {"role": "user", "content": prompt}  # 用户的问题或推理内容
                ],
                max_tokens=1500,  # 可根据需要设置响应内容的长度
                temperature=0.7, # 控制生成内容的随机性
                timeout=30 
            )

            # 提取返回的文本内容
            response_text = response.choices[0].message.content
            
            return response_text

        except Exception as e:
            logger.error(f"Error during API call for {self.name}: {str(e)}")
            return ""


    def compile_solution(self, steps):
        solution_text = ""
        for title, content in steps:
            solution_text += f"### {title}\n{content}\n\n"
        return solution_text

================
File: app.py
================
import openai
from openai import OpenAI

import os

os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'

openai.api_key = os.getenv("OPENAI_API_KEY")  # 或者直接在代码中设置 API 密钥

client = OpenAI()

completion = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {
            "role": "user",
            "content": """Response Format:

Respond in JSON format with the following keys:

- `"title"`: A brief title for the reasoning step.
- `"content"`: Detailed explanation of the reasoning step.
- `"next_action"`: `"continue"` to proceed with more steps or `"final_answer"` if you are confident in your solution.

**Example Response:**

```json
{
    "title": "Applying Advanced Concepts",
    "content": "To enhance the solution, I will...",
    "next_action": "continue"
}```"""
        }
    ]
)

print(completion.choices[0].message.content)

================
File: main.py
================
# main.py

import logging
import os
import time  
from agents.agent_factory import AgentFactory
from utils.user_input_handler import get_user_input
from utils.result_formatter import format_results
import openai

os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'

# Ensure logs directory exists
logs_dir = os.path.join(os.path.dirname(__file__), 'logs')
if not os.path.exists(logs_dir):
    os.makedirs(logs_dir)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    filename='logs/system.log',
    filemode='w',
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Configure the Gemini API
openai.api_key = os.getenv("OPENAI_API_KEY")

def main():
    # Step 1: User Input Handler
    user_problem = get_user_input()
    logger.info("User problem received: %s", user_problem)

    # Step 2: Sequential Processing through Agents
    agent_factory = AgentFactory()
    agents = agent_factory.create_agents()  # Returns the list of agents in sequence

    previous_solution = None
    all_solutions = []

    for agent in agents:
        solution = agent.get_solution(user_problem, previous_solution)
        all_solutions.append((agent.name, solution))
        previous_solution = solution  # Pass the current solution to the next agent

    # Step 3: Final Output
    final_solution = previous_solution

    # Step 4: Result Formatting and Output
    formatted_result = format_results(all_solutions, final_solution)
    print("Final Answer:")
    print(final_solution)
    print("\nDetailed Reasoning and Steps:")
    print(formatted_result)

if __name__ == "__main__":
    main()

================
File: README.md
================
# Agent-0: Replicating O1's Chain of Thought Reasoning

**[Watch the Video Overview](https://youtu.be/Oasl9rSJNds)**  
For a detailed walkthrough of how this project works and what to expect, check out the video linked above.

## Project Description

This project is a **proof of concept** that aims to replicate the reasoning capabilities of OpenAI's newly released O1 model. O1 uses chain-of-thought prompting and reinforcement learning to reflect on its solutions, improving responses through iterative reasoning. Our goal is to mimic this behavior using alternative models.

In this implementation, we use a sequential agent-based system powered by the Gemini API (or any model with function-calling capabilities). The system proposes solutions to coding-related problems and iteratively refines them using chain-of-thought and reflection techniques at each stage. The Gemini API, with its code execution abilities, is ideal for this project. While it works with Gemini Flash, we recommend using the Pro version to avoid issues with external package dependencies, as the Pro version generally sticks to Python's standard library.

## Important Note

This is a **very early version** and was created as a **weekend hack**, so expect it to fail in various scenarios. It currently works best for problems that can be solved through coding. We encourage you to give it a try and **report any bugs or issues** you encounter.

## How to Run

### 1. Set Environment Variable

You need to set an environment variable for your Google API key:
```bash
export GOOGLE_API_KEY=<your_api_key>
```

### 2. Run the Script

```bash
python main.py
```

### 2. Create a Conda Virtual Environment

It's recommended to use a Conda environment for this project. To create and activate a new Conda environment:

```bash
conda create -n agent-0 python=3.10
conda activate agent-0
```

### 3. Install Dependencies

The only dependency required for this project is google-generativeai. Install it using pip:

```bash
pip install google-generativeai
```

### 4. Run the Script

```bash
python main.py
```

Give it a try and let us know what you think! Make sure to give it a star if you enjoyed it.

================
File: utils/result_formatter.py
================
def format_results(all_solutions, final_solution):
    formatted_text = ""
    formatted_text += "=== Agent Solutions ===\n\n"
    for agent_name, solution_text in all_solutions:
        formatted_text += f"--- {agent_name} ---\n{solution_text}\n\n"
    formatted_text += "=== Final Synthesized Solution ===\n\n"
    formatted_text += final_solution + "\n\n"
    return formatted_text

================
File: utils/user_input_handler.py
================
def get_user_input():
    print("Please enter your problem or query:")
    return input()
